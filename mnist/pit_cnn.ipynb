{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten #, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D, MaxPool2D, LSTM\n",
    "from keras        import regularizers, initializers\n",
    "from scipy.signal import detrend\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = tk.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data() \n",
    " \n",
    "# Normalize pixel values within 0 and 1 \n",
    "train_images = train_images / 255 \n",
    "test_images  = test_images / 255\n",
    "\n",
    "valid_frac = 0.3\n",
    "N = len(train_labels)\n",
    "N_valid = int(N*valid_frac)\n",
    "N_train = N - N_valid\n",
    "\n",
    "val_images = train_images[0:N_valid]\n",
    "val_labels = train_labels[0:N_valid]\n",
    "train_images = train_images[N_valid:]\n",
    "train_labels = train_labels[N_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n"
     ]
    }
   ],
   "source": [
    "plot_input(train_images, train_labels,5)\n",
    "plot_input(val_images, val_labels,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(np.unique(train_labels, return_counts=False))\n",
    "\n",
    "#grace scale\n",
    "train_images = train_images.reshape(\n",
    "    train_images.shape[0],\n",
    "    train_images.shape[1],\n",
    "    train_images.shape[2],\n",
    "    1)\n",
    "val_images = val_images.reshape(\n",
    "    val_images.shape[0],\n",
    "    val_images.shape[1],\n",
    "    val_images.shape[2],\n",
    "    1)\n",
    "test_images = test_images.reshape(\n",
    "    test_images.shape[0],\n",
    "    test_images.shape[1],\n",
    "    test_images.shape[2],\n",
    "    1)\n",
    "\n",
    "# train_labels = tk.utils.to_categorical(train_labels, n_class)\n",
    "# val_labels = tk.utils.to_categorical(val_labels, n_class)\n",
    "# test_labels = tk.utils.to_categorical(test_labels, n_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 11, 11, 16)        4624      \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 9, 9, 8)           1160      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 4, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,394\n",
      "Trainable params: 7,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential(name=\"pcnn\")\n",
    "\n",
    "model2.add(Conv2D(\n",
    "    32, #number of nodes\n",
    "    kernel_size = 3, \n",
    "    activation  ='relu',\n",
    "    input_shape = (28,28,1)\n",
    "    ))\n",
    "model2.add(MaxPool2D(pool_size=2))\n",
    "model2.add(Conv2D(16, kernel_size = 3, activation  ='relu'))\n",
    "model2.add(Conv2D(8, kernel_size = 3, activation  ='relu'))\n",
    "model2.add(MaxPool2D(pool_size=2))\n",
    "model2.add(Flatten()) #per connettere conv e dense\n",
    "model2.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers='Adam'\n",
    "\n",
    "# compile\n",
    "model2.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "657/657 [==============================] - 16s 23ms/step - loss: 0.4064 - accuracy: 0.8733 - val_loss: 0.1517 - val_accuracy: 0.9539\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.1206 - accuracy: 0.9634 - val_loss: 0.1142 - val_accuracy: 0.9666\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0918 - accuracy: 0.9720 - val_loss: 0.0961 - val_accuracy: 0.9717\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0769 - accuracy: 0.9766 - val_loss: 0.0811 - val_accuracy: 0.9749\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0654 - accuracy: 0.9799 - val_loss: 0.0668 - val_accuracy: 0.9794\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 17s 26ms/step - loss: 0.0526 - accuracy: 0.9840 - val_loss: 0.0663 - val_accuracy: 0.9791\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.0674 - val_accuracy: 0.9802\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0440 - accuracy: 0.9866 - val_loss: 0.0586 - val_accuracy: 0.9822\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0404 - accuracy: 0.9871 - val_loss: 0.0570 - val_accuracy: 0.9826\n",
      "Epoch 11/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.0581 - val_accuracy: 0.9832\n",
      "Epoch 12/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 0.0582 - val_accuracy: 0.9839\n",
      "Epoch 13/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 14/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0508 - val_accuracy: 0.9851\n",
      "Epoch 15/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0598 - val_accuracy: 0.9840\n",
      "Epoch 16/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0555 - val_accuracy: 0.9836\n",
      "Epoch 17/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0493 - val_accuracy: 0.9857\n",
      "Epoch 18/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.0474 - val_accuracy: 0.9867\n",
      "Epoch 19/20\n",
      "657/657 [==============================] - 16s 25ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0522 - val_accuracy: 0.9863\n",
      "Epoch 20/20\n",
      "657/657 [==============================] - 16s 24ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0516 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b8c2eefc40>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model2.fit(\n",
    "    train_images, train_labels, \n",
    "    batch_size=64, \n",
    "    validation_data=(val_images, val_labels), \n",
    "    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict(test_images[:1])\n",
    "# for i in range(1):\n",
    "#     plot_input(test_images, test_labels,i)\n",
    "#     plot_input(test_images, pred[i], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NN(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        architecture      = None,\n",
    "        dropout_layers    = None,\n",
    "        dropout_rates     = None,\n",
    "        batch_norm_layers = None,\n",
    "        initializer       = \"glorot_uniform\",\n",
    "        hidden_activation = \"sigmoid\",\n",
    "        output_activation = \"sigmoid\",\n",
    "        nn_name           = \"my neural network\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Neural Network Model\n",
    "\n",
    "        Arguments:\n",
    "        input_dim         [int]    -> number of features in data               e.g. 2\n",
    "        architecture      [list]   -> neural network architecture              e.g. [2, 3, 3, 1]\n",
    "        dropout_layers    [list]   -> list of dropout layers                   e.g. [3, 4]\n",
    "        dropout_rates     [list]   -> list of dropout rates                    e.g. [0.2, 0.5]\n",
    "        batch_norm_layers [list]   -> list of batch normalization layers       e.g. [1, 2]\n",
    "        initializers      [list]   -> list of weights initializers per layer   e.g. [\"zeros\", \"ones\", \"glorot_uniform\"]\n",
    "        hidden_activation [string] -> activation function for hidden layers    e.g. relu\n",
    "        output_activation [string] -> activation function for the output layer e.g. sigmoid\n",
    "        name              [string] -> model name \n",
    "        \"\"\"\n",
    "        # initialize parent class\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # store the model name\n",
    "        self.nn_name = nn_name\n",
    "\n",
    "        # store the number of features \n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # store weights initializers\n",
    "        self.w_init = initializer\n",
    "\n",
    "        # store dropout architecture\n",
    "        self.dropout_arc   = dropout_layers\n",
    "        self.dropout_rates = dropout_rates\n",
    "\n",
    "        if self.dropout_arc is not None:\n",
    "            self.dropout       = [ \n",
    "                tf.keras.layers.Dropout(\n",
    "                    self.dropout_rates[i], \n",
    "                    name=f\"dropout_{self.dropout_arc[i]-1}\"\n",
    "                )\n",
    "                for i in range(len(self.dropout_arc))\n",
    "            ]\n",
    "\n",
    "        # store batch normalization architecture\n",
    "        self.batch_norm_arc = batch_norm_layers\n",
    "\n",
    "        if self.batch_norm_arc is not None:\n",
    "            self.batch_norm     = [\n",
    "                tf.keras.layers.BatchNormalization(\n",
    "                    name=f\"batch_norm_{self.batch_norm_arc[i]-1}\"\n",
    "                )\n",
    "                for i in range(len(self.batch_norm_arc))\n",
    "            ]\n",
    "\n",
    "        # create the input layer with input_dim neurons\n",
    "        self.input_layer = tf.keras.layers.Input(shape=self.input_dim, name=\"input_layer\")\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            tf.keras.layers.Dense(\n",
    "                architecture[i+1], \n",
    "                input_shape        = (architecture[i],), \n",
    "                activation         = hidden_activation,\n",
    "                kernel_initializer = self.w_init,\n",
    "                name               = f\"hidden_{i}\"\n",
    "            )\n",
    "            for i in range(len(architecture)-2)\n",
    "        ]\n",
    "\n",
    "        # create hidden layers following architecture\n",
    "        #if len(self.w_init) == 1:\n",
    "        #    self.hidden_layers = [\n",
    "        #        tf.keras.layers.Dense(\n",
    "        #            architecture[i+1], \n",
    "        #            input_shape        = (architecture[i],), \n",
    "        #            activation         = hidden_activation,\n",
    "        #            kernel_initializer = self.w_init[0],\n",
    "        #            name               = f\"hidden_{i}\"\n",
    "        #        )\n",
    "        #        for i in range(len(architecture)-2)\n",
    "        #    ]\n",
    "        #elif len(self.w_init) > 1:\n",
    "        #    self.hidden_layers = [\n",
    "        #        tf.keras.layers.Dense(\n",
    "        #            architecture[i+1], \n",
    "        #            input_shape        = (architecture[i],), \n",
    "        #            activation         = hidden_activation,\n",
    "        #            kernel_initializer = self.w_init[i],\n",
    "        #            name               = f\"hidden_{i}\"\n",
    "        #        )\n",
    "        #        for i in range(len(architecture)-2)\n",
    "        #    ]\n",
    "\n",
    "        # create the output layer\n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            architecture[-1], \n",
    "            input_shape = (architecture[-2],), \n",
    "            activation  = output_activation, \n",
    "            name        = \"output_layer\"\n",
    "        )\n",
    "\n",
    "        # build the model \n",
    "        self.build(input_shape=(None, self.input_dim))\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"the call method deals with model creation\"\"\"\n",
    "\n",
    "        batch_norm_counter = 0\n",
    "        dropout_counter    = 0\n",
    "\n",
    "        # for each hidden layer, feed it with the previous one\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "\n",
    "            # build batch normalization layer before hidden layer\n",
    "            if self.batch_norm_arc is not None and (i+1) in self.batch_norm_arc:\n",
    "                x = self.batch_norm[batch_norm_counter](x)\n",
    "                batch_norm_counter = batch_norm_counter +1\n",
    "\n",
    "            # build the hidden layer\n",
    "            x = hidden_layer(x)\n",
    "\n",
    "            # build dropout layer after hidden layer\n",
    "            if self.dropout_arc is not None and (i+1) in self.dropout_arc:\n",
    "                x = self.dropout[dropout_counter](x)\n",
    "                dropout_counter = dropout_counter + 1\n",
    "            \n",
    "        # feed the output layer with the last hidden layer\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        # returns the computed output layer\n",
    "        return x\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"re-define summary method to fix the output_shape : multiple issue\"\"\"\n",
    "\n",
    "        # create a temporary model with all the computed shapes (thanks to self.call method)\n",
    "        model = tf.keras.Model(\n",
    "            inputs  = [self.input_layer], \n",
    "            outputs = self.call(self.input_layer),\n",
    "            name    = self.nn_name\n",
    "        )\n",
    "\n",
    "        # return the model summary with computed shapes\n",
    "        return model.summary(line_length=100)\n",
    "    \n",
    "\n",
    "def create_model(\n",
    "    input_dim,\n",
    "    architecture,\n",
    "    dropout_layers    = None,\n",
    "    dropout_rates     = None,\n",
    "    batch_norm_layers = None,\n",
    "    hidden_activation = \"relu\",\n",
    "    output_activation = \"sigmoid\",\n",
    "    initializer       = \"glorot_uniform\",\n",
    "    loss              = \"binary_crossentropy\",\n",
    "    optimizer         = \"adam\",\n",
    "    metrics           = [\"accuracy\"],\n",
    "    nn_name           = \"model\",\n",
    "):\n",
    "\n",
    "    # build the NN model\n",
    "    model = NN(\n",
    "        input_dim         = input_dim,\n",
    "        architecture      = architecture,\n",
    "        dropout_layers    = dropout_layers,\n",
    "        dropout_rates     = dropout_rates,\n",
    "        batch_norm_layers = batch_norm_layers,\n",
    "        hidden_activation = hidden_activation,\n",
    "        output_activation = output_activation,\n",
    "        initializer       = initializer,\n",
    "        nn_name           = nn_name,\n",
    "    )\n",
    "    # compile the NN model\n",
    "    model.compile(\n",
    "        loss      = loss,\n",
    "        optimizer = optimizer,\n",
    "        metrics   = metrics,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3994a27638cfa6c2546c6ba1f9185499b0aad7759b87cd55c1e26d1cb9172b48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
