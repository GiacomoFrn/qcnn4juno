{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten #, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D, MaxPool2D\n",
    "from keras        import regularizers, initializers\n",
    "from scipy.signal import detrend\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = tk.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data() \n",
    " \n",
    "# Reduce dataset size \n",
    "# train_images = train_images[:n_train] \n",
    "# train_labels = train_labels[:n_train] \n",
    "# test_images  = test_images[:n_test] \n",
    "# test_labels  = test_labels[:n_test] \n",
    " \n",
    "# Normalize pixel values within 0 and 1 \n",
    "train_images = train_images / 255 \n",
    "test_images  = test_images / 255\n",
    "\n",
    "valid_frac = 0.3\n",
    "N = len(train_labels)\n",
    "N_valid = int(N*valid_frac)\n",
    "N_train = N - N_valid\n",
    "\n",
    "val_images = train_images[0:N_valid]\n",
    "val_labels = train_labels[0:N_valid]\n",
    "train_images = train_images[N_valid:]\n",
    "train_labels = train_labels[N_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n"
     ]
    }
   ],
   "source": [
    "plot_input(train_images,train_labels,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N       = len(train_images)\n",
    "n_class = len(np.unique(train_labels, return_counts=False))\n",
    "input_shape = train_images.shape\n",
    "type(input_shape)\n",
    "input_shape = (28,28,1)\n",
    "input_s = tuple(input_shape)\n",
    "input_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pccnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 18, 18, 4)         488       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 9, 9, 4)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 3, 5)           985       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 3)           138       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                132       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,913\n",
      "Trainable params: 1,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reg = regularizers.l2(0.02)\n",
    "ini = keras.initializers.RandomNormal(mean = 0.0, stddev=0.05, seed =None)\n",
    "\n",
    "NF = 4\n",
    "\n",
    "model = Sequential(name=\"pccnn\")\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters            = NF, \n",
    "        kernel_size        = 11, \n",
    "        kernel_initializer = ini,\n",
    "        kernel_regularizer = reg,\n",
    "        activation         = 'relu',\n",
    "        input_shape        = input_s\n",
    "    )\n",
    ")\n",
    "model.add(MaxPool2D(pool_size=2)) # average of 5 values\n",
    "model.add(Conv2D(filters=5, kernel_size=7, activation='relu'))\n",
    "model.add(Conv2D(filters=3, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = tf.keras.optimizers='Adam'\n",
    "\n",
    "# compile\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 250\n",
    "EPOCHS     = 100\n",
    "\n",
    "fit = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size      = BATCH_SIZE,\n",
    "    epochs          = EPOCHS, \n",
    "    validation_data = (x_val, y_val),\n",
    "    verbose         = 0, \n",
    "    shuffle         = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NN(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        architecture      = None,\n",
    "        dropout_layers    = None,\n",
    "        dropout_rates     = None,\n",
    "        batch_norm_layers = None,\n",
    "        initializer       = \"glorot_uniform\",\n",
    "        hidden_activation = \"sigmoid\",\n",
    "        output_activation = \"sigmoid\",\n",
    "        nn_name           = \"my neural network\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Neural Network Model\n",
    "\n",
    "        Arguments:\n",
    "        input_dim         [int]    -> number of features in data               e.g. 2\n",
    "        architecture      [list]   -> neural network architecture              e.g. [2, 3, 3, 1]\n",
    "        dropout_layers    [list]   -> list of dropout layers                   e.g. [3, 4]\n",
    "        dropout_rates     [list]   -> list of dropout rates                    e.g. [0.2, 0.5]\n",
    "        batch_norm_layers [list]   -> list of batch normalization layers       e.g. [1, 2]\n",
    "        initializers      [list]   -> list of weights initializers per layer   e.g. [\"zeros\", \"ones\", \"glorot_uniform\"]\n",
    "        hidden_activation [string] -> activation function for hidden layers    e.g. relu\n",
    "        output_activation [string] -> activation function for the output layer e.g. sigmoid\n",
    "        name              [string] -> model name \n",
    "        \"\"\"\n",
    "        # initialize parent class\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # store the model name\n",
    "        self.nn_name = nn_name\n",
    "\n",
    "        # store the number of features \n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # store weights initializers\n",
    "        self.w_init = initializer\n",
    "\n",
    "        # store dropout architecture\n",
    "        self.dropout_arc   = dropout_layers\n",
    "        self.dropout_rates = dropout_rates\n",
    "\n",
    "        if self.dropout_arc is not None:\n",
    "            self.dropout       = [ \n",
    "                tf.keras.layers.Dropout(\n",
    "                    self.dropout_rates[i], \n",
    "                    name=f\"dropout_{self.dropout_arc[i]-1}\"\n",
    "                )\n",
    "                for i in range(len(self.dropout_arc))\n",
    "            ]\n",
    "\n",
    "        # store batch normalization architecture\n",
    "        self.batch_norm_arc = batch_norm_layers\n",
    "\n",
    "        if self.batch_norm_arc is not None:\n",
    "            self.batch_norm     = [\n",
    "                tf.keras.layers.BatchNormalization(\n",
    "                    name=f\"batch_norm_{self.batch_norm_arc[i]-1}\"\n",
    "                )\n",
    "                for i in range(len(self.batch_norm_arc))\n",
    "            ]\n",
    "\n",
    "        # create the input layer with input_dim neurons\n",
    "        self.input_layer = tf.keras.layers.Input(shape=self.input_dim, name=\"input_layer\")\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            tf.keras.layers.Dense(\n",
    "                architecture[i+1], \n",
    "                input_shape        = (architecture[i],), \n",
    "                activation         = hidden_activation,\n",
    "                kernel_initializer = self.w_init,\n",
    "                name               = f\"hidden_{i}\"\n",
    "            )\n",
    "            for i in range(len(architecture)-2)\n",
    "        ]\n",
    "\n",
    "        # create hidden layers following architecture\n",
    "        #if len(self.w_init) == 1:\n",
    "        #    self.hidden_layers = [\n",
    "        #        tf.keras.layers.Dense(\n",
    "        #            architecture[i+1], \n",
    "        #            input_shape        = (architecture[i],), \n",
    "        #            activation         = hidden_activation,\n",
    "        #            kernel_initializer = self.w_init[0],\n",
    "        #            name               = f\"hidden_{i}\"\n",
    "        #        )\n",
    "        #        for i in range(len(architecture)-2)\n",
    "        #    ]\n",
    "        #elif len(self.w_init) > 1:\n",
    "        #    self.hidden_layers = [\n",
    "        #        tf.keras.layers.Dense(\n",
    "        #            architecture[i+1], \n",
    "        #            input_shape        = (architecture[i],), \n",
    "        #            activation         = hidden_activation,\n",
    "        #            kernel_initializer = self.w_init[i],\n",
    "        #            name               = f\"hidden_{i}\"\n",
    "        #        )\n",
    "        #        for i in range(len(architecture)-2)\n",
    "        #    ]\n",
    "\n",
    "        # create the output layer\n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            architecture[-1], \n",
    "            input_shape = (architecture[-2],), \n",
    "            activation  = output_activation, \n",
    "            name        = \"output_layer\"\n",
    "        )\n",
    "\n",
    "        # build the model \n",
    "        self.build(input_shape=(None, self.input_dim))\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"the call method deals with model creation\"\"\"\n",
    "\n",
    "        batch_norm_counter = 0\n",
    "        dropout_counter    = 0\n",
    "\n",
    "        # for each hidden layer, feed it with the previous one\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "\n",
    "            # build batch normalization layer before hidden layer\n",
    "            if self.batch_norm_arc is not None and (i+1) in self.batch_norm_arc:\n",
    "                x = self.batch_norm[batch_norm_counter](x)\n",
    "                batch_norm_counter = batch_norm_counter +1\n",
    "\n",
    "            # build the hidden layer\n",
    "            x = hidden_layer(x)\n",
    "\n",
    "            # build dropout layer after hidden layer\n",
    "            if self.dropout_arc is not None and (i+1) in self.dropout_arc:\n",
    "                x = self.dropout[dropout_counter](x)\n",
    "                dropout_counter = dropout_counter + 1\n",
    "            \n",
    "        # feed the output layer with the last hidden layer\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        # returns the computed output layer\n",
    "        return x\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"re-define summary method to fix the output_shape : multiple issue\"\"\"\n",
    "\n",
    "        # create a temporary model with all the computed shapes (thanks to self.call method)\n",
    "        model = tf.keras.Model(\n",
    "            inputs  = [self.input_layer], \n",
    "            outputs = self.call(self.input_layer),\n",
    "            name    = self.nn_name\n",
    "        )\n",
    "\n",
    "        # return the model summary with computed shapes\n",
    "        return model.summary(line_length=100)\n",
    "    \n",
    "\n",
    "def create_model(\n",
    "    input_dim,\n",
    "    architecture,\n",
    "    dropout_layers    = None,\n",
    "    dropout_rates     = None,\n",
    "    batch_norm_layers = None,\n",
    "    hidden_activation = \"relu\",\n",
    "    output_activation = \"sigmoid\",\n",
    "    initializer       = \"glorot_uniform\",\n",
    "    loss              = \"binary_crossentropy\",\n",
    "    optimizer         = \"adam\",\n",
    "    metrics           = [\"accuracy\"],\n",
    "    nn_name           = \"model\",\n",
    "):\n",
    "\n",
    "    # build the NN model\n",
    "    model = NN(\n",
    "        input_dim         = input_dim,\n",
    "        architecture      = architecture,\n",
    "        dropout_layers    = dropout_layers,\n",
    "        dropout_rates     = dropout_rates,\n",
    "        batch_norm_layers = batch_norm_layers,\n",
    "        hidden_activation = hidden_activation,\n",
    "        output_activation = output_activation,\n",
    "        initializer       = initializer,\n",
    "        nn_name           = nn_name,\n",
    "    )\n",
    "    # compile the NN model\n",
    "    model.compile(\n",
    "        loss      = loss,\n",
    "        optimizer = optimizer,\n",
    "        metrics   = metrics,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3994a27638cfa6c2546c6ba1f9185499b0aad7759b87cd55c1e26d1cb9172b48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
