{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCNN tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "colors = [\n",
    "    \"#7eb0d5\",\n",
    "    \"#fd7f6f\",\n",
    "    \"#b2e061\",\n",
    "    \"#bd7ebe\",\n",
    "    \"#ffb55a\",\n",
    "    \"#8bd3c7\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import distributions\n",
    "\n",
    "\n",
    "class QuantumConv2d(nn.Conv2d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 eps,\n",
    "                 cap,\n",
    "                 ratio,\n",
    "                 delta,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1):\n",
    "        \"\"\"Base class for quantum convolutional layer.\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): number of input channels.\n",
    "            out_channels (int): number of output channels.\n",
    "            kernel_size (int): size of the convolution kernel.\n",
    "            eps (float): precision of quantum multiplication.\n",
    "            cap (float): value for cap 'relu' activation function.\n",
    "            ratio (float): precision of quantum tomography.\n",
    "            delta (float): precision of quantum gradient estimation.\n",
    "            stride (int, optional): convolution stride. Defaults to 1.\n",
    "            padding (int, optional): convolution padding. Defaults to 0.\n",
    "            dilation (int, optional): convolution dilation. Defaults to 1.\n",
    "        \"\"\"\n",
    "        # convolution layer\n",
    "        super(QuantumConv2d, self).__init__(in_channels,\n",
    "                                            out_channels,\n",
    "                                            kernel_size,\n",
    "                                            stride=stride,\n",
    "                                            padding=padding,\n",
    "                                            dilation=dilation,\n",
    "                                            groups=1,\n",
    "                                            bias=False,\n",
    "                                            padding_mode='zeros')\n",
    "\n",
    "        # set/check quantum parameters\n",
    "        self.set_quantum_params(eps, cap, ratio, delta)\n",
    "\n",
    "        # unfold operation\n",
    "        self.unfold = nn.Unfold(kernel_size, dilation, padding, stride)\n",
    "\n",
    "        # gradient operation\n",
    "        self.weight.register_hook(self.simulate_quantum_gradient)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        # get convolutional layer output\n",
    "        output = super(QuantumConv2d, self).forward(input)\n",
    "        output = torch.clamp(output, 0., self.cap)\n",
    "\n",
    "        # get quantum output\n",
    "        quantum_output = self.simulate_quantum_output(input, output)\n",
    "\n",
    "        # update convolutional layer output\n",
    "        output.data = quantum_output.data\n",
    "\n",
    "        return output\n",
    "\n",
    "    def simulate_quantum_output(self, input, output):\n",
    "        with torch.no_grad():\n",
    "            if self.eps > 0.:\n",
    "                # get kernel norm\n",
    "                kernel_matrix = self.weight.data.flatten(start_dim=1)\n",
    "                kernel_matrix = kernel_matrix.transpose(0, 1)\n",
    "                kernel_norm = torch.norm(kernel_matrix, dim=0)\n",
    "                kernel_norm = kernel_norm.repeat(input.size(0), 1, 1)\n",
    "\n",
    "                # get input norm\n",
    "                input_matrix = self.unfold(input)\n",
    "                input_matrix = input_matrix.transpose(1, 2)\n",
    "                input_norm = torch.norm(input_matrix, dim=2)\n",
    "                input_norm = input_norm.unsqueeze(2)\n",
    "\n",
    "                # add gaussian noise\n",
    "                product_norm = torch.bmm(input_norm, kernel_norm)\n",
    "                product_norm = product_norm.reshape(output.shape)\n",
    "                noise = torch.randn(output.shape, device=output.device)\n",
    "                output += 2 * self.eps * product_norm * noise\n",
    "                output = torch.clamp(output, 0., self.cap)\n",
    "\n",
    "            if self.ratio < 1.:\n",
    "                # quantum sampling\n",
    "                num_samples = int(self.ratio * output.shape[1:].numel())\n",
    "                probs = output.flatten(start_dim=1)\n",
    "                distribution = distributions.Categorical(probs=probs)\n",
    "                samples = distribution.sample((num_samples, )).flatten()\n",
    "                idxs = torch.arange(0, input.size(0))\n",
    "                idxs = idxs.repeat(1, num_samples).flatten()\n",
    "                mask = torch.zeros_like(probs)\n",
    "                mask[idxs, samples] = 1.\n",
    "                mask = mask.reshape(output.shape)\n",
    "                output = mask * output\n",
    "        return output\n",
    "\n",
    "    def simulate_quantum_gradient(self, grad):\n",
    "        if self.delta > 0.:\n",
    "            # add quantum gradient estimation error to the kernel\n",
    "            noise = torch.randn(grad.shape, device=grad.device)\n",
    "            grad_norm = torch.norm(grad)\n",
    "            error = self.delta * grad_norm * noise\n",
    "            grad += error\n",
    "        return grad\n",
    "\n",
    "    def set_quantum_params(self, eps=None, cap=None, ratio=None, delta=None):\n",
    "        if eps is not None:\n",
    "            assert 0. <= eps <= 1., 'epsilon should verify: 0.<=eps<=1.'\n",
    "            self.eps = eps\n",
    "        if cap is not None:\n",
    "            assert 0. < cap, 'cap should verify: 0.<cap'\n",
    "            self.cap = cap\n",
    "        if ratio is not None:\n",
    "            assert 0. < ratio <= 1., 'ratio should verify: 0.<ratio<=1.'\n",
    "            self.ratio = ratio\n",
    "        if delta is not None:\n",
    "            assert 0 <= delta <= 1., 'delta should verify: 0.<=delta<=1.'\n",
    "            self.delta = delta\n",
    "\n",
    "    def convert_to_classical(self):\n",
    "        layer = nn.Conv2d(self.in_channels,\n",
    "                          self.out_channels,\n",
    "                          self.kernel_size,\n",
    "                          self.stride,\n",
    "                          self.padding,\n",
    "                          self.dilation,\n",
    "                          groups=1,\n",
    "                          bias=False,\n",
    "                          padding_mode='zeros')\n",
    "        layer.weight.data = self.weight.data\n",
    "        return layer\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = '{in_channels}, {out_channels}, kernel_size={kernel_size}, '\n",
    "        s += 'quantum_eps={eps}, quantum_cap = {cap}, '\n",
    "        s += 'quantum_ratio={ratio}, quantum_delta = {delta}, '\n",
    "        s += 'stride={stride}'\n",
    "        if self.padding != (0, ) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1, ) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        return s.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim, # n_samples, image size and channels\n",
    "        n_classes, # dimension of one-hot encoded labels\n",
    "        conv_activation    = \"relu\",\n",
    "        hidden_activation  = \"relu\",\n",
    "        cnn_name           = \"my convo neural network\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        # initialize parent class\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # store the model name\n",
    "        self.cnn_name = cnn_name\n",
    "\n",
    "        self.input_layer = tf.keras.layers.Input(shape=input_dim[1:], name=\"input\")\n",
    "        \n",
    "        self.conv_1  = tf.keras.layers.Conv2D(32, (3, 3), activation=conv_activation, input_shape=input_dim[1:], name=\"conv_1\")\n",
    "        self.pool_1  = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool_1\")\n",
    "        self.conv_2  = tf.keras.layers.Conv2D(64, (3, 3), activation=conv_activation, name=\"conv_2\")\n",
    "        self.conv_3  = tf.keras.layers.Conv2D(64, (3, 3), activation=conv_activation, name=\"conv_3\")\n",
    "        self.pool_2  = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool_2\")\n",
    "        self.flatten = tf.keras.layers.Flatten(name=\"flatten\")\n",
    "        self.dense_1 = tf.keras.layers.Dense(100, activation=hidden_activation, name=\"dense_1\")\n",
    "        self.out     = tf.keras.layers.Dense(n_classes, activation=\"softmax\", name=\"output\")\n",
    "        \n",
    "        self.build(input_shape=input_dim)\n",
    "\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"the call method deals with model creation\"\"\"\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        \n",
    "        return self.out(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"re-define summary method to fix the output_shape : multiple issue\"\"\"\n",
    "\n",
    "        # create a temporary model with all the computed shapes (thanks to self.call method)\n",
    "        model = tf.keras.Model(\n",
    "            inputs  = [self.input_layer], \n",
    "            outputs = self.call(self.input_layer),\n",
    "            name    = self.cnn_name\n",
    "        )\n",
    "\n",
    "        # return the model summary with computed shapes\n",
    "        return model.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grey-scale ==> 1 channel\n",
    "trainX = trainX.reshape(trainX.shape[0], trainX.shape[1], trainX.shape[2], 1)\n",
    "testX  = testX.reshape(testX.shape[0], testX.shape[1], testX.shape[2], 1)\n",
    "\n",
    "# pixel normalization\n",
    "trainX = trainX.astype(\"float32\")\n",
    "testX  = testX.astype(\"float32\")\n",
    "trainX = trainX / 255\n",
    "testX  = testX / 255\n",
    "\n",
    "# label one-hot encoding\n",
    "trainY = tf.keras.utils.to_categorical(trainY)\n",
    "testY  = tf.keras.utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91e94dacc13bcc9ab92871d8572d4c8a018895bdfb2528d081f4892614b17d07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
