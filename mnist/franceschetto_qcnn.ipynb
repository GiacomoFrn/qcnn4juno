{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= tf.cast(x_train, tf.float32)\n",
    "x_test=tf.cast(x_test, tf.float32)\n",
    "\n",
    "x_train = tf.image.resize(x_train[:], (10,10)).numpy()\n",
    "x_test = tf.image.resize(x_test[:], (10,10)).numpy()\n",
    "\n",
    "y_train = y_train[:]\n",
    "y_test = y_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "fig = plt.figure()\n",
    "plt.imshow(x_train[0, :, :, 0], cmap='gray_r')\n",
    "plt.colorbar()\n",
    "fig.savefig('sample', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = np.shape(x_train)[1]\n",
    "height = np.shape(x_train)[2]\n",
    "\n",
    "cnn_model = models.Sequential()\n",
    "\n",
    "cnn_model.add(layers.Conv2D(8, (2, 2), activation='relu', input_shape=(width, height, 1)))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
    "\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(32, activation='relu'))\n",
    "cnn_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 9, 9, 8)           40        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 648)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                20768     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,138\n",
      "Trainable params: 21,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 6s 10ms/step - loss: 1.0706 - accuracy: 0.6808 - val_loss: 0.6268 - val_accuracy: 0.8120\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.5049 - accuracy: 0.8520 - val_loss: 0.4197 - val_accuracy: 0.8767\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4494 - accuracy: 0.8648 - val_loss: 0.3567 - val_accuracy: 0.8968\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.4267 - accuracy: 0.8704 - val_loss: 0.3925 - val_accuracy: 0.8811\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.3763 - accuracy: 0.8888 - val_loss: 0.3231 - val_accuracy: 0.9005\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.3385 - accuracy: 0.8976 - val_loss: 0.3397 - val_accuracy: 0.9011\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.3186 - accuracy: 0.8984 - val_loss: 0.2962 - val_accuracy: 0.9120\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.3390 - accuracy: 0.8920 - val_loss: 0.2851 - val_accuracy: 0.9169\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.3031 - accuracy: 0.9104 - val_loss: 0.3589 - val_accuracy: 0.8904\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.2816 - accuracy: 0.9160 - val_loss: 0.2657 - val_accuracy: 0.9222\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.3064 - accuracy: 0.9104 - val_loss: 0.2491 - val_accuracy: 0.9282\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.2778 - accuracy: 0.9164 - val_loss: 0.2473 - val_accuracy: 0.9257\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.2685 - accuracy: 0.9220 - val_loss: 0.2317 - val_accuracy: 0.9302\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.2484 - accuracy: 0.9176 - val_loss: 0.2305 - val_accuracy: 0.9328\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.2558 - accuracy: 0.9212 - val_loss: 0.2306 - val_accuracy: 0.9318\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.2541 - accuracy: 0.9204 - val_loss: 0.2504 - val_accuracy: 0.9266\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.2167 - accuracy: 0.9344 - val_loss: 0.2084 - val_accuracy: 0.9379\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.2208 - accuracy: 0.9324 - val_loss: 0.2199 - val_accuracy: 0.9330\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.2505 - accuracy: 0.9188 - val_loss: 0.2285 - val_accuracy: 0.9292\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.2329 - accuracy: 0.9308 - val_loss: 0.2012 - val_accuracy: 0.9384\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1969 - accuracy: 0.9416 - val_loss: 0.2028 - val_accuracy: 0.9385\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.2014 - accuracy: 0.9376 - val_loss: 0.1855 - val_accuracy: 0.9438\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.1928 - accuracy: 0.9420 - val_loss: 0.2008 - val_accuracy: 0.9382\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.2251 - accuracy: 0.9336 - val_loss: 0.1756 - val_accuracy: 0.9448\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1760 - accuracy: 0.9444 - val_loss: 0.1758 - val_accuracy: 0.9450\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.1885 - accuracy: 0.9436 - val_loss: 0.1882 - val_accuracy: 0.9414\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1902 - accuracy: 0.9396 - val_loss: 0.1695 - val_accuracy: 0.9503\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1929 - accuracy: 0.9444 - val_loss: 0.1838 - val_accuracy: 0.9453\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1891 - accuracy: 0.9380 - val_loss: 0.1841 - val_accuracy: 0.9441\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1859 - accuracy: 0.9460 - val_loss: 0.1736 - val_accuracy: 0.9477\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1875 - accuracy: 0.9416 - val_loss: 0.1701 - val_accuracy: 0.9471\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1670 - accuracy: 0.9492 - val_loss: 0.1554 - val_accuracy: 0.9528\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.1956 - accuracy: 0.9400 - val_loss: 0.1544 - val_accuracy: 0.9524\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.1722 - accuracy: 0.9484 - val_loss: 0.1715 - val_accuracy: 0.9494\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1961 - accuracy: 0.9376 - val_loss: 0.1680 - val_accuracy: 0.9477\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.1624 - accuracy: 0.9448 - val_loss: 0.1544 - val_accuracy: 0.9522\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.1945 - accuracy: 0.9444 - val_loss: 0.1687 - val_accuracy: 0.9478\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1655 - accuracy: 0.9484 - val_loss: 0.1569 - val_accuracy: 0.9503\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1635 - accuracy: 0.9492 - val_loss: 0.1766 - val_accuracy: 0.9465\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1688 - accuracy: 0.9436 - val_loss: 0.1577 - val_accuracy: 0.9520\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1626 - accuracy: 0.9492 - val_loss: 0.1427 - val_accuracy: 0.9563\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1731 - accuracy: 0.9464 - val_loss: 0.1567 - val_accuracy: 0.9520\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1376 - accuracy: 0.9548 - val_loss: 0.1587 - val_accuracy: 0.9531\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1567 - accuracy: 0.9492 - val_loss: 0.1595 - val_accuracy: 0.9528\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1513 - accuracy: 0.9520 - val_loss: 0.1482 - val_accuracy: 0.9537\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1445 - accuracy: 0.9532 - val_loss: 0.1508 - val_accuracy: 0.9545\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1655 - accuracy: 0.9484 - val_loss: 0.1387 - val_accuracy: 0.9579\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.1704 - accuracy: 0.9468 - val_loss: 0.1386 - val_accuracy: 0.9579\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1427 - accuracy: 0.9544 - val_loss: 0.1357 - val_accuracy: 0.9601\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1207 - accuracy: 0.9604 - val_loss: 0.1398 - val_accuracy: 0.9563\n"
     ]
    }
   ],
   "source": [
    "cnn_model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn_history = cnn_model.fit(x_train, y_train, steps_per_epoch=500,\n",
    "                        validation_data=(x_test, y_test), \n",
    "                        epochs=50, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_size, depth, activation=None, name=None, kernel_regularizer=None, **kwangs):\n",
    "        super(QConv, self).__init__(name=name, **kwangs)\n",
    "        self.filter_size = filter_size\n",
    "        self.depth = depth\n",
    "        self.learning_params = []\n",
    "        self.QCNN_layer_gen()\n",
    "        # self.circuit_tensor = tfq.convert_to_tensor([self.circuit])\n",
    "        self.activation = tf.keras.layers.Activation(activation)\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "    def _next_qubit_set(self, original_size, next_size, qubits):\n",
    "        step = original_size // next_size\n",
    "        qubit_list = []\n",
    "        for i in range(0, original_size, step):\n",
    "            for j in range(0, original_size, step):\n",
    "                qubit_list.append(qubits[original_size*i + j])\n",
    "        return qubit_list\n",
    "\n",
    "    def _get_new_param(self):\n",
    "        \"\"\"\n",
    "        return new learnable parameter\n",
    "        all returned parameter saved in self.learning_params\n",
    "        \"\"\"\n",
    "        new_param = sympy.symbols(\"p\"+str(len(self.learning_params)))\n",
    "        self.learning_params.append(new_param)\n",
    "        return new_param\n",
    "    \n",
    "    def _QConv(self, step, target, qubits):\n",
    "        \"\"\"\n",
    "        apply learnable gates each quantum convolutional layer level\n",
    "        \"\"\"\n",
    "        yield cirq.CZPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
    "        yield cirq.CXPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
    "    \n",
    "    def QCNN_layer_gen(self):\n",
    "        \"\"\"\n",
    "        make quantum convolutional layer in QConv layer\n",
    "        \"\"\"\n",
    "        pixels = self.filter_size**2\n",
    "        # filter size: 2^n only for this version!\n",
    "        if np.log2(pixels) % 1 != 0:\n",
    "            raise NotImplementedError(\"filter size: 2^n only available\")\n",
    "        cirq_qubits = cirq.GridQubit.rect(self.filter_size, self.filter_size)\n",
    "        # mapping input data to circuit\n",
    "        input_circuit = cirq.Circuit()\n",
    "        input_params = [sympy.symbols('a%d' %i) for i in range(pixels)]\n",
    "        for i, qubit in enumerate(cirq_qubits):\n",
    "            input_circuit.append(cirq.rx(np.pi*input_params[i])(qubit))\n",
    "        # apply learnable gate set to QCNN circuit\n",
    "        QCNN_circuit = cirq.Circuit()\n",
    "        step_size = [2**i for i in range(np.log2(pixels).astype(np.int32))]\n",
    "        for step in step_size:\n",
    "            for target in range(0, pixels, 2*step):\n",
    "                QCNN_circuit.append(self._QConv(step, target, cirq_qubits))\n",
    "        # merge the circuits\n",
    "        full_circuit = cirq.Circuit()\n",
    "        full_circuit.append(input_circuit)\n",
    "        full_circuit.append(QCNN_circuit)\n",
    "        self.circuit = full_circuit # save circuit to the QCNN layer obj.\n",
    "        self.params = input_params + self.learning_params\n",
    "        self.op = cirq.Z(cirq_qubits[0])\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.width = input_shape[1]\n",
    "        self.height = input_shape[2]\n",
    "        self.channel = input_shape[3]\n",
    "        self.num_x = self.width - self.filter_size + 1\n",
    "        self.num_y = self.height - self.filter_size + 1\n",
    "        \n",
    "        self.kernel = self.add_weight(name=\"kenel\", \n",
    "                                      shape=[self.depth, \n",
    "                                             self.channel, \n",
    "                                             len(self.learning_params)],\n",
    "                                     initializer=tf.keras.initializers.glorot_normal(),\n",
    "                                     regularizer=self.kernel_regularizer)\n",
    "        self.circuit_tensor = tfq.convert_to_tensor([self.circuit] * self.num_x * self.num_y * self.channel)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # input shape: [N, width, height, channel]\n",
    "        # slide and collect data\n",
    "        stack_set = None\n",
    "        for i in range(self.num_x):\n",
    "            for j in range(self.num_y):\n",
    "                slice_part = tf.slice(inputs, [0, i, j, 0], [-1, self.filter_size, self.filter_size, -1])\n",
    "                slice_part = tf.reshape(slice_part, shape=[-1, 1, self.filter_size, self.filter_size, self.channel])\n",
    "                if stack_set == None:\n",
    "                    stack_set = slice_part\n",
    "                else:\n",
    "                    stack_set = tf.concat([stack_set, slice_part], 1)  \n",
    "        # -> shape: [N, num_x*num_y, filter_size, filter_size, channel]\n",
    "        stack_set = tf.transpose(stack_set, perm=[0, 1, 4, 2, 3])\n",
    "        # -> shape: [N, num_x*num_y, channel, filter_size, fiter_size]\n",
    "        stack_set = tf.reshape(stack_set, shape=[-1, self.filter_size**2])\n",
    "        # -> shape: [N*num_x*num_y*channel, filter_size^2]\n",
    "        \n",
    "        # total input citcuits: N * num_x * num_y * channel\n",
    "        circuit_inputs = tf.tile([self.circuit_tensor], [tf.shape(inputs)[0], 1])\n",
    "        circuit_inputs = tf.reshape(circuit_inputs, shape=[-1])\n",
    "        tf.fill([tf.shape(inputs)[0]*self.num_x*self.num_y, 1], 1)\n",
    "        outputs = []\n",
    "        for i in range(self.depth):\n",
    "            controller = tf.tile(self.kernel[i], [tf.shape(inputs)[0]*self.num_x*self.num_y, 1])\n",
    "            outputs.append(self.single_depth_QCNN(stack_set, controller, circuit_inputs))\n",
    "            # shape: [N, num_x, num_y] \n",
    "            \n",
    "        output_tensor = tf.stack(outputs, axis=3)\n",
    "        output_tensor = tf.math.acos(tf.clip_by_value(output_tensor, -1+1e-5, 1-1e-5)) / np.pi\n",
    "        # output_tensor = tf.clip_by_value(tf.math.acos(output_tensor)/np.pi, -1, 1)\n",
    "        return self.activation(output_tensor)\n",
    "    \n",
    "    def single_depth_QCNN(self, input_data, controller, circuit_inputs):\n",
    "        \"\"\"\n",
    "        make QCNN for 1 channel only\n",
    "        \"\"\"\n",
    "        # input shape: [N*num_x*num_y*channel, filter_size^2]\n",
    "        # controller shape: [N*num_x*num_y*channel, len(learning_params)]\n",
    "        input_data = tf.concat([input_data, controller], 1)\n",
    "        # input_data shape: [N*num_x*num_y*channel, len(learning_params)]\n",
    "        QCNN_output = tfq.layers.Expectation()(circuit_inputs, \n",
    "                                               symbol_names=self.params,\n",
    "                                               symbol_values=input_data,\n",
    "                                               operators=self.op)\n",
    "        # QCNN_output shape: [N*num_x*num_y*channel]\n",
    "        QCNN_output = tf.reshape(QCNN_output, shape=[-1, self.num_x, self.num_y, self.channel])\n",
    "        return tf.math.reduce_sum(QCNN_output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = np.shape(x_train)[1]\n",
    "height = np.shape(x_train)[2]\n",
    "\n",
    "qcnn_model = models.Sequential()\n",
    "\n",
    "\n",
    "qcnn_model.add(QConv(filter_size=2, depth=8, activation='relu', \n",
    "                     name='qconv1', input_shape=(width, height, 1)))\n",
    "#model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
    "qcnn_model.add(layers.Flatten())\n",
    "qcnn_model.add(layers.Dense(32, activation='relu'))\n",
    "qcnn_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " qconv1 (QConv)              (None, 9, 9, 8)           48        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 648)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                20768     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,146\n",
      "Trainable params: 21,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"606.96109375\" height=\"200.0\"><line x1=\"34.7588671875\" x2=\"576.96109375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"576.96109375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"576.96109375\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"576.96109375\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"324.25851562500003\" x2=\"324.25851562500003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"324.25851562500003\" x2=\"324.25851562500003\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"393.88220703125\" x2=\"393.88220703125\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"393.88220703125\" x2=\"393.88220703125\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"463.5780859375\" x2=\"463.5780859375\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"533.22365234375\" x2=\"533.22365234375\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"79.51773437499999\" y=\"5.0\" width=\"198.90484375000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"178.97015625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(3.14159265358979*a0)</text><rect x=\"79.51773437499999\" y=\"55.0\" width=\"198.90484375000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"178.97015625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(3.14159265358979*a1)</text><rect x=\"79.51773437499999\" y=\"105.0\" width=\"198.90484375000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"178.97015625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(3.14159265358979*a2)</text><rect x=\"79.51773437499999\" y=\"155.0\" width=\"198.90484375000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"178.97015625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(3.14159265358979*a3)</text><circle cx=\"324.25851562500003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"298.42257812500003\" y=\"55.0\" width=\"51.671875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.25851562500003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^p0</text><circle cx=\"324.25851562500003\" cy=\"125.0\" r=\"10.0\" /><rect x=\"298.42257812500003\" y=\"155.0\" width=\"51.671875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.25851562500003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^p2</text><circle cx=\"393.88220703125\" cy=\"25.0\" r=\"10.0\" /><rect x=\"370.094453125\" y=\"55.0\" width=\"47.57550781250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"393.88220703125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^p1</text><circle cx=\"393.88220703125\" cy=\"125.0\" r=\"10.0\" /><rect x=\"370.094453125\" y=\"155.0\" width=\"47.57550781250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"393.88220703125\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^p3</text><circle cx=\"463.5780859375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"437.66996093750004\" y=\"105.0\" width=\"51.81625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"463.5780859375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^p4</text><circle cx=\"533.22365234375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"509.4862109375\" y=\"105.0\" width=\"47.4748828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"533.22365234375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^p5</text></svg>",
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f49c43eb250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(QConv(filter_size=2, depth=0, activation='relu').circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 205s 4s/step - loss: 0.5546 - accuracy: 0.8320 - val_loss: 0.4491 - val_accuracy: 0.8657\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 221s 4s/step - loss: 0.4059 - accuracy: 0.8600 - val_loss: 0.4456 - val_accuracy: 0.8671\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 226s 5s/step - loss: 0.5728 - accuracy: 0.8320 - val_loss: 0.4296 - val_accuracy: 0.8739\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 242s 5s/step - loss: 0.4518 - accuracy: 0.8760 - val_loss: 0.4431 - val_accuracy: 0.8706\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 231s 5s/step - loss: 0.4596 - accuracy: 0.8560 - val_loss: 0.4467 - val_accuracy: 0.8673\n"
     ]
    }
   ],
   "source": [
    "qcnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "qcnn_history = qcnn_model.fit(x_train, y_train, steps_per_epoch=50,\n",
    "                        validation_data=(x_test, y_test), \n",
    "                        epochs=5, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c764765d3a23b82ea6dc8b51e68f828b52dfa8d66dff00b67cebce7fa206e036"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
