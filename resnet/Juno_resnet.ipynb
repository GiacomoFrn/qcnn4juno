{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, Input, Add, \\\n",
    "                         Activation, ZeroPadding2D, BatchNormalization, \\\n",
    "                         AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 10:16:03.156331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 10:16:03.194352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 10:16:03.194545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primo blocco conv, NON Ã¨ un residual block!\\\n",
    "Con input shape = (230,124,2) ==> output del layer shape = (51, 57, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1(X, filters = 32 , block=\"conv1\", stage=2):\n",
    "            \n",
    "        # defining name basis\n",
    "        conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "        \n",
    "        X_input = X\n",
    "        # First component of main path\n",
    "        X = Conv2D(filters, kernel_size = (6,3), strides = (2,1),\n",
    "                name = conv_name_base + '2a',\n",
    "                #nchannels??\n",
    "                # data_format=\"channels_first\", \n",
    "                # kernel_initializer = glorot_uniform(seed=0)\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis = 1, name = bn_name_base + '2a')(X)\n",
    "        X = Activation('relu')(X)\n",
    "        \n",
    "        # Second component of main path\n",
    "        X = Conv2D(filters, kernel_size = (3,3), strides = (2,2),\n",
    "                name = conv_name_base + '2b',\n",
    "                #nchannels?? \n",
    "                # kernel_initializer = glorot_uniform(seed=0)\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis=1, name = bn_name_base + '2b')(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = MaxPooling2D((3,3), strides=(1, 1))(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_input = Input(shape=(219,122,2)) \n",
    "\n",
    "# res1 = conv1(X_input)\n",
    "# res1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual block Model: function that takes in input the numbers of filters and the stride of the convolutional layer.\\\n",
    "In this way this block can be used for all the residual blocks of the ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2x(X, stride, filters, block,stage=2):\n",
    "        # defining name basis\n",
    "        conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "        #filters for each ==> there are two filters because 4 layer \n",
    "        #                     --> the first 2 and the last 2 have the same f \n",
    "        f1,f2 = filters\n",
    "        s = stride\n",
    "        #skip path for the residual part\n",
    "        X_shortcut = Conv2D(f2, kernel_size = (3,3), strides = (s,s),\n",
    "                name = conv_name_base + '-shortcut',\n",
    "                )(X)\n",
    "\n",
    "        X_shortcut = BatchNormalization(axis=1, name = bn_name_base + '-shortcut')(X_shortcut)\n",
    "\n",
    "        # First component of main path\n",
    "        X = Conv2D(f1, kernel_size = (1,1), strides = (1,1),\n",
    "                name = conv_name_base + '2a',\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis = 1, name = bn_name_base + '2a')(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        # Second component of main path\n",
    "        X = Conv2D(f1, kernel_size = (3,3), strides = (s,s),\n",
    "                name = conv_name_base + '2b',\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis=1, name = bn_name_base + '2b')(X)\n",
    "        X = Activation('relu')(X)\n",
    "        \n",
    "        # Second component of main path\n",
    "        X = Conv2D(f2, kernel_size = (1,1), strides = (1,1),\n",
    "                name = conv_name_base + '2c',\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis=1, name = bn_name_base + '2c')(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = Add()([X, X_shortcut])\n",
    "        out = Activation('relu')(X)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, initial_learning_rate, epochs, steps_per_epoch):\n",
    "    self.initial_learning_rate = initial_learning_rate\n",
    "    self.steps_per_epoch = steps_per_epoch\n",
    "    self.m = initial_learning_rate / steps_per_epoch\n",
    "    self.decay_rate = (10**-8 / initial_learning_rate)**(((epochs - 1)*steps_per_epoch)**-1)\n",
    "    print('decay_rate:', self.decay_rate)\n",
    "\n",
    "  def __call__(self, step):\n",
    "    result = tf.cond(tf.less(step, self.steps_per_epoch), \n",
    "                   lambda: self.m * (step+1),\n",
    "                   lambda: self.initial_learning_rate * tf.math.pow(self.decay_rate, (step+1-self.steps_per_epoch)))\n",
    "\n",
    "    tf.print('lr at step', step, 'is', result, output_stream='file://learning_rates.txt')\n",
    "    return result  \n",
    "    '''if step < self.steps_per_epoch:\n",
    "      return self.m * (step + 1)\n",
    "    else:\n",
    "      return self.initial_learning_rate * self.decay_rate**step'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_input = Input(shape=( 24, 26, 256)) \n",
    "\n",
    "# res2 = conv2x(X_input, stride=2, filters=[128,512], block=\"a\")\n",
    "# res2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetJ(feature, lr_power=-3.0, epochs=15, steps_per_epoch=55):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    Arguments:\n",
    "        feature is a string which allow two input values:\n",
    "        --> 'vertex' or 'energy'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    # X_input = Input(shape=(230,124,2))\n",
    "    X_input = Input(shape=(230,124,2))\n",
    "    \n",
    "    # Stage 1\n",
    "    X = conv1(X_input, block=\"conv1\")\n",
    "    # Stage2\n",
    "    X = conv2x(X, stride=1, filters=[32,128], block=\"conv2x_1\")\n",
    "    X = conv2x(X, stride=1, filters=[32,128], block=\"conv2x_2\")\n",
    "    X = conv2x(X, stride=1, filters=[32,128], block=\"conv2x_3\")\n",
    "\n",
    "    # Stage 3\n",
    "    # X = conv2x(X, stride=2, filters=[64,256], block=\"conv3x_1\")\n",
    "    X = conv2x(X, stride=1, filters=[64,256], block=\"conv3x_2\")\n",
    "    X = conv2x(X, stride=1, filters=[64,256], block=\"conv3x_3\")\n",
    "    X = conv2x(X, stride=1, filters=[64,256], block=\"conv3x_4\")\n",
    "\n",
    "    # Stage 4 \n",
    "    # X = conv2x(X, stride=2, filters=[128,512], block=\"conv4x_1\")\n",
    "    X = conv2x(X, stride=1, filters=[128,512], block=\"conv4x_2\")\n",
    "    X = conv2x(X, stride=1, filters=[128,512], block=\"conv4x_3\")\n",
    "    X = conv2x(X, stride=1, filters=[128,512], block=\"conv4x_4\")\n",
    "    X = conv2x(X, stride=1, filters=[128,512], block=\"conv4x_5\")\n",
    "    X = conv2x(X, stride=1, filters=[128,512], block=\"conv4x_6\")\n",
    "\n",
    "    # Stage 5\n",
    "    X = conv2x(X, stride=2, filters=[256,1024], block=\"conv5x_1\")\n",
    "    X = conv2x(X, stride=1, filters=[256,1024], block=\"conv5x_2\")\n",
    "    X = conv2x(X, stride=1, filters=[256,1024], block=\"conv5x_3\")\n",
    "\n",
    "    \"\"\"\n",
    "    prova con i filters originali del papaer ma senza i blocchi rossi\n",
    "    \"\"\"\n",
    "    # Stage 1\n",
    "    # X = conv1(X_input, block=\"conv1\")\n",
    "    # # Stage2\n",
    "    # X = conv2x(X, stride=1, filters=[64,256], block=\"conv2x_1\")\n",
    "    # # X = conv2x(X, stride=1, filters=[64,256], block=\"conv2x_2\")\n",
    "    # # X = conv2x(X, stride=1, filters=[64,256], block=\"conv2x_3\")\n",
    "\n",
    "    # # Stage 3\n",
    "    # X = conv2x(X, stride=2, filters=[64,256], block=\"conv3x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[128,512], block=\"conv3x_2\")\n",
    "    # # X = conv2x(X, stride=1, filters=[128,512], block=\"conv3x_3\")\n",
    "    # # X = conv2x(X, stride=1, filters=[128,512], block=\"conv3x_4\")\n",
    "\n",
    "    # # Stage 4 \n",
    "    # X = conv2x(X, stride=2, filters=[128,512], block=\"conv4x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_2\")\n",
    "    # # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_3\")\n",
    "    # # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_4\")\n",
    "    # # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_5\")\n",
    "    # # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_6\")\n",
    "\n",
    "    # # Stage 5\n",
    "    # X = conv2x(X, stride=2, filters=[512,2048], block=\"conv5x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[512,2048], block=\"conv5x_2\")\n",
    "    # # X = conv2x(X, stride=1, filters=[512,2048], block=\"conv5x_3\")\n",
    "\n",
    "    # AVGPOOL \n",
    "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
    "    # Flatten\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512, name='first_dense',  kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = Dense(100, name='second_dense', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Output \n",
    "    if(feature==\"energy\"):\n",
    "        X = Dense(1, name='fc_outputs', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    elif(feature==\"vertex\"):\n",
    "        X = Dense(3, name='fc_outputs', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name = 'ResNetJ')\n",
    "    \n",
    "    # Compile model\n",
    "    learning_rate = 10.0**(lr_power)\n",
    "    opt = tk.optimizers.Adam(learning_rate=MyLRSchedule(learning_rate, epochs, steps_per_epoch), beta_1 = 0.9, beta_2 = 0.999 )\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename  = '../../juno_data/data/projections/proj_raw_data_train_0.npz'\n",
    "labelname = '../../juno_data/data/real/train/targets/targets_train_0.csv'\n",
    "x_train = np.load(filename, allow_pickle=True)['arr_0']\n",
    "\n",
    "# nan to zero \n",
    "x_train[np.isnan(x_train)] = 0\n",
    "\n",
    "y_train = pd.read_csv(labelname)\n",
    "y_train = y_train['edep'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "decay_rate: 0.9896444748193868\n",
      "Model: \"ResNetJ\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 230, 124, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " res2conv1_branch2a (Conv2D)    (None, 113, 122, 32  1184        ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv1_branch2a (BatchNormal  (None, 113, 122, 32  452        ['res2conv1_branch2a[0][0]']     \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 113, 122, 32  0           ['bn2conv1_branch2a[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2conv1_branch2b (Conv2D)    (None, 56, 60, 32)   9248        ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv1_branch2b (BatchNormal  (None, 56, 60, 32)  224         ['res2conv1_branch2b[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 56, 60, 32)   0           ['bn2conv1_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 54, 58, 32)  0           ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " res2conv2x_1_branch2a (Conv2D)  (None, 54, 58, 32)  1056        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " bn2conv2x_1_branch2a (BatchNor  (None, 54, 58, 32)  216         ['res2conv2x_1_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 54, 58, 32)   0           ['bn2conv2x_1_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv2x_1_branch2b (Conv2D)  (None, 52, 56, 32)  9248        ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_1_branch2b (BatchNor  (None, 52, 56, 32)  208         ['res2conv2x_1_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 52, 56, 32)   0           ['bn2conv2x_1_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv2x_1_branch2c (Conv2D)  (None, 52, 56, 128)  4224       ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_1_branch2c (BatchNor  (None, 52, 56, 128)  208        ['res2conv2x_1_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv2x_1_branch-shortcut (  (None, 52, 56, 128)  36992      ['max_pooling2d_4[0][0]']        \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 52, 56, 128)  0           ['bn2conv2x_1_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv2x_1_branch-shortcut (B  (None, 52, 56, 128)  208        ['res2conv2x_1_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 52, 56, 128)  0           ['activation_236[0][0]',         \n",
      "                                                                  'bn2conv2x_1_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 52, 56, 128)  0           ['add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv2x_2_branch2a (Conv2D)  (None, 52, 56, 32)  4128        ['activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_2_branch2a (BatchNor  (None, 52, 56, 32)  208         ['res2conv2x_2_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 52, 56, 32)   0           ['bn2conv2x_2_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv2x_2_branch2b (Conv2D)  (None, 50, 54, 32)  9248        ['activation_238[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_2_branch2b (BatchNor  (None, 50, 54, 32)  200         ['res2conv2x_2_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 50, 54, 32)   0           ['bn2conv2x_2_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv2x_2_branch2c (Conv2D)  (None, 50, 54, 128)  4224       ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_2_branch2c (BatchNor  (None, 50, 54, 128)  200        ['res2conv2x_2_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv2x_2_branch-shortcut (  (None, 50, 54, 128)  147584     ['activation_237[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 50, 54, 128)  0           ['bn2conv2x_2_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv2x_2_branch-shortcut (B  (None, 50, 54, 128)  200        ['res2conv2x_2_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 50, 54, 128)  0           ['activation_240[0][0]',         \n",
      "                                                                  'bn2conv2x_2_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 50, 54, 128)  0           ['add_57[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv2x_3_branch2a (Conv2D)  (None, 50, 54, 32)  4128        ['activation_241[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_3_branch2a (BatchNor  (None, 50, 54, 32)  200         ['res2conv2x_3_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 50, 54, 32)   0           ['bn2conv2x_3_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv2x_3_branch2b (Conv2D)  (None, 48, 52, 32)  9248        ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_3_branch2b (BatchNor  (None, 48, 52, 32)  192         ['res2conv2x_3_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 48, 52, 32)   0           ['bn2conv2x_3_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv2x_3_branch2c (Conv2D)  (None, 48, 52, 128)  4224       ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv2x_3_branch2c (BatchNor  (None, 48, 52, 128)  192        ['res2conv2x_3_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv2x_3_branch-shortcut (  (None, 48, 52, 128)  147584     ['activation_241[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 48, 52, 128)  0           ['bn2conv2x_3_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv2x_3_branch-shortcut (B  (None, 48, 52, 128)  192        ['res2conv2x_3_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 48, 52, 128)  0           ['activation_244[0][0]',         \n",
      "                                                                  'bn2conv2x_3_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 48, 52, 128)  0           ['add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv3x_2_branch2a (Conv2D)  (None, 48, 52, 64)  8256        ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_2_branch2a (BatchNor  (None, 48, 52, 64)  192         ['res2conv3x_2_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 48, 52, 64)   0           ['bn2conv3x_2_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv3x_2_branch2b (Conv2D)  (None, 46, 50, 64)  36928       ['activation_246[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_2_branch2b (BatchNor  (None, 46, 50, 64)  184         ['res2conv3x_2_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 46, 50, 64)   0           ['bn2conv3x_2_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv3x_2_branch2c (Conv2D)  (None, 46, 50, 256)  16640      ['activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_2_branch2c (BatchNor  (None, 46, 50, 256)  184        ['res2conv3x_2_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv3x_2_branch-shortcut (  (None, 46, 50, 256)  295168     ['activation_245[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 46, 50, 256)  0           ['bn2conv3x_2_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv3x_2_branch-shortcut (B  (None, 46, 50, 256)  184        ['res2conv3x_2_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 46, 50, 256)  0           ['activation_248[0][0]',         \n",
      "                                                                  'bn2conv3x_2_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 46, 50, 256)  0           ['add_59[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv3x_3_branch2a (Conv2D)  (None, 46, 50, 64)  16448       ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_3_branch2a (BatchNor  (None, 46, 50, 64)  184         ['res2conv3x_3_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 46, 50, 64)   0           ['bn2conv3x_3_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv3x_3_branch2b (Conv2D)  (None, 44, 48, 64)  36928       ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_3_branch2b (BatchNor  (None, 44, 48, 64)  176         ['res2conv3x_3_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 44, 48, 64)   0           ['bn2conv3x_3_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv3x_3_branch2c (Conv2D)  (None, 44, 48, 256)  16640      ['activation_251[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_3_branch2c (BatchNor  (None, 44, 48, 256)  176        ['res2conv3x_3_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv3x_3_branch-shortcut (  (None, 44, 48, 256)  590080     ['activation_249[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 44, 48, 256)  0           ['bn2conv3x_3_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv3x_3_branch-shortcut (B  (None, 44, 48, 256)  176        ['res2conv3x_3_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 44, 48, 256)  0           ['activation_252[0][0]',         \n",
      "                                                                  'bn2conv3x_3_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 44, 48, 256)  0           ['add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv3x_4_branch2a (Conv2D)  (None, 44, 48, 64)  16448       ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_4_branch2a (BatchNor  (None, 44, 48, 64)  176         ['res2conv3x_4_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 44, 48, 64)   0           ['bn2conv3x_4_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv3x_4_branch2b (Conv2D)  (None, 42, 46, 64)  36928       ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_4_branch2b (BatchNor  (None, 42, 46, 64)  168         ['res2conv3x_4_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 42, 46, 64)   0           ['bn2conv3x_4_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv3x_4_branch2c (Conv2D)  (None, 42, 46, 256)  16640      ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv3x_4_branch2c (BatchNor  (None, 42, 46, 256)  168        ['res2conv3x_4_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv3x_4_branch-shortcut (  (None, 42, 46, 256)  590080     ['activation_253[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 42, 46, 256)  0           ['bn2conv3x_4_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv3x_4_branch-shortcut (B  (None, 42, 46, 256)  168        ['res2conv3x_4_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 42, 46, 256)  0           ['activation_256[0][0]',         \n",
      "                                                                  'bn2conv3x_4_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 42, 46, 256)  0           ['add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv4x_2_branch2a (Conv2D)  (None, 42, 46, 128)  32896      ['activation_257[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_2_branch2a (BatchNor  (None, 42, 46, 128)  168        ['res2conv4x_2_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 42, 46, 128)  0           ['bn2conv4x_2_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_2_branch2b (Conv2D)  (None, 40, 44, 128)  147584     ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_2_branch2b (BatchNor  (None, 40, 44, 128)  160        ['res2conv4x_2_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 40, 44, 128)  0           ['bn2conv4x_2_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_2_branch2c (Conv2D)  (None, 40, 44, 512)  66048      ['activation_259[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_2_branch2c (BatchNor  (None, 40, 44, 512)  160        ['res2conv4x_2_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv4x_2_branch-shortcut (  (None, 40, 44, 512)  1180160    ['activation_257[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 40, 44, 512)  0           ['bn2conv4x_2_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv4x_2_branch-shortcut (B  (None, 40, 44, 512)  160        ['res2conv4x_2_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 40, 44, 512)  0           ['activation_260[0][0]',         \n",
      "                                                                  'bn2conv4x_2_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_261 (Activation)    (None, 40, 44, 512)  0           ['add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv4x_3_branch2a (Conv2D)  (None, 40, 44, 128)  65664      ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_3_branch2a (BatchNor  (None, 40, 44, 128)  160        ['res2conv4x_3_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 40, 44, 128)  0           ['bn2conv4x_3_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_3_branch2b (Conv2D)  (None, 38, 42, 128)  147584     ['activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_3_branch2b (BatchNor  (None, 38, 42, 128)  152        ['res2conv4x_3_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 38, 42, 128)  0           ['bn2conv4x_3_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_3_branch2c (Conv2D)  (None, 38, 42, 512)  66048      ['activation_263[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_3_branch2c (BatchNor  (None, 38, 42, 512)  152        ['res2conv4x_3_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv4x_3_branch-shortcut (  (None, 38, 42, 512)  2359808    ['activation_261[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 38, 42, 512)  0           ['bn2conv4x_3_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv4x_3_branch-shortcut (B  (None, 38, 42, 512)  152        ['res2conv4x_3_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 38, 42, 512)  0           ['activation_264[0][0]',         \n",
      "                                                                  'bn2conv4x_3_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_265 (Activation)    (None, 38, 42, 512)  0           ['add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv4x_4_branch2a (Conv2D)  (None, 38, 42, 128)  65664      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_4_branch2a (BatchNor  (None, 38, 42, 128)  152        ['res2conv4x_4_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_266 (Activation)    (None, 38, 42, 128)  0           ['bn2conv4x_4_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_4_branch2b (Conv2D)  (None, 36, 40, 128)  147584     ['activation_266[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_4_branch2b (BatchNor  (None, 36, 40, 128)  144        ['res2conv4x_4_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_267 (Activation)    (None, 36, 40, 128)  0           ['bn2conv4x_4_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_4_branch2c (Conv2D)  (None, 36, 40, 512)  66048      ['activation_267[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_4_branch2c (BatchNor  (None, 36, 40, 512)  144        ['res2conv4x_4_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv4x_4_branch-shortcut (  (None, 36, 40, 512)  2359808    ['activation_265[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_268 (Activation)    (None, 36, 40, 512)  0           ['bn2conv4x_4_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv4x_4_branch-shortcut (B  (None, 36, 40, 512)  144        ['res2conv4x_4_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 36, 40, 512)  0           ['activation_268[0][0]',         \n",
      "                                                                  'bn2conv4x_4_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_269 (Activation)    (None, 36, 40, 512)  0           ['add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv4x_5_branch2a (Conv2D)  (None, 36, 40, 128)  65664      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_5_branch2a (BatchNor  (None, 36, 40, 128)  144        ['res2conv4x_5_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_270 (Activation)    (None, 36, 40, 128)  0           ['bn2conv4x_5_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_5_branch2b (Conv2D)  (None, 34, 38, 128)  147584     ['activation_270[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_5_branch2b (BatchNor  (None, 34, 38, 128)  136        ['res2conv4x_5_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_271 (Activation)    (None, 34, 38, 128)  0           ['bn2conv4x_5_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_5_branch2c (Conv2D)  (None, 34, 38, 512)  66048      ['activation_271[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_5_branch2c (BatchNor  (None, 34, 38, 512)  136        ['res2conv4x_5_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv4x_5_branch-shortcut (  (None, 34, 38, 512)  2359808    ['activation_269[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_272 (Activation)    (None, 34, 38, 512)  0           ['bn2conv4x_5_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv4x_5_branch-shortcut (B  (None, 34, 38, 512)  136        ['res2conv4x_5_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 34, 38, 512)  0           ['activation_272[0][0]',         \n",
      "                                                                  'bn2conv4x_5_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_273 (Activation)    (None, 34, 38, 512)  0           ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv4x_6_branch2a (Conv2D)  (None, 34, 38, 128)  65664      ['activation_273[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_6_branch2a (BatchNor  (None, 34, 38, 128)  136        ['res2conv4x_6_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_274 (Activation)    (None, 34, 38, 128)  0           ['bn2conv4x_6_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_6_branch2b (Conv2D)  (None, 32, 36, 128)  147584     ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_6_branch2b (BatchNor  (None, 32, 36, 128)  128        ['res2conv4x_6_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_275 (Activation)    (None, 32, 36, 128)  0           ['bn2conv4x_6_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv4x_6_branch2c (Conv2D)  (None, 32, 36, 512)  66048      ['activation_275[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv4x_6_branch2c (BatchNor  (None, 32, 36, 512)  128        ['res2conv4x_6_branch2c[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " res2conv4x_6_branch-shortcut (  (None, 32, 36, 512)  2359808    ['activation_273[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " activation_276 (Activation)    (None, 32, 36, 512)  0           ['bn2conv4x_6_branch2c[0][0]']   \n",
      "                                                                                                  \n",
      " bn2conv4x_6_branch-shortcut (B  (None, 32, 36, 512)  128        ['res2conv4x_6_branch-shortcut[0]\n",
      " atchNormalization)                                              [0]']                            \n",
      "                                                                                                  \n",
      " add_66 (Add)                   (None, 32, 36, 512)  0           ['activation_276[0][0]',         \n",
      "                                                                  'bn2conv4x_6_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_277 (Activation)    (None, 32, 36, 512)  0           ['add_66[0][0]']                 \n",
      "                                                                                                  \n",
      " res2conv5x_1_branch2a (Conv2D)  (None, 32, 36, 256)  131328     ['activation_277[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv5x_1_branch2a (BatchNor  (None, 32, 36, 256)  128        ['res2conv5x_1_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_278 (Activation)    (None, 32, 36, 256)  0           ['bn2conv5x_1_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv5x_1_branch2b (Conv2D)  (None, 15, 17, 256)  590080     ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv5x_1_branch2b (BatchNor  (None, 15, 17, 256)  60         ['res2conv5x_1_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_279 (Activation)    (None, 15, 17, 256)  0           ['bn2conv5x_1_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv5x_1_branch2c (Conv2D)  (None, 15, 17, 1024  263168     ['activation_279[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv5x_1_branch2c (BatchNor  (None, 15, 17, 1024  60         ['res2conv5x_1_branch2c[0][0]']  \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " res2conv5x_1_branch-shortcut (  (None, 15, 17, 1024  4719616    ['activation_277[0][0]']         \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_280 (Activation)    (None, 15, 17, 1024  0           ['bn2conv5x_1_branch2c[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv5x_1_branch-shortcut (B  (None, 15, 17, 1024  60         ['res2conv5x_1_branch-shortcut[0]\n",
      " atchNormalization)             )                                [0]']                            \n",
      "                                                                                                  \n",
      " add_67 (Add)                   (None, 15, 17, 1024  0           ['activation_280[0][0]',         \n",
      "                                )                                 'bn2conv5x_1_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_281 (Activation)    (None, 15, 17, 1024  0           ['add_67[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2conv5x_2_branch2a (Conv2D)  (None, 15, 17, 256)  262400     ['activation_281[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv5x_2_branch2a (BatchNor  (None, 15, 17, 256)  60         ['res2conv5x_2_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_282 (Activation)    (None, 15, 17, 256)  0           ['bn2conv5x_2_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv5x_2_branch2b (Conv2D)  (None, 13, 15, 256)  590080     ['activation_282[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv5x_2_branch2b (BatchNor  (None, 13, 15, 256)  52         ['res2conv5x_2_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_283 (Activation)    (None, 13, 15, 256)  0           ['bn2conv5x_2_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv5x_2_branch2c (Conv2D)  (None, 13, 15, 1024  263168     ['activation_283[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv5x_2_branch2c (BatchNor  (None, 13, 15, 1024  52         ['res2conv5x_2_branch2c[0][0]']  \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " res2conv5x_2_branch-shortcut (  (None, 13, 15, 1024  9438208    ['activation_281[0][0]']         \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_284 (Activation)    (None, 13, 15, 1024  0           ['bn2conv5x_2_branch2c[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv5x_2_branch-shortcut (B  (None, 13, 15, 1024  52         ['res2conv5x_2_branch-shortcut[0]\n",
      " atchNormalization)             )                                [0]']                            \n",
      "                                                                                                  \n",
      " add_68 (Add)                   (None, 13, 15, 1024  0           ['activation_284[0][0]',         \n",
      "                                )                                 'bn2conv5x_2_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_285 (Activation)    (None, 13, 15, 1024  0           ['add_68[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2conv5x_3_branch2a (Conv2D)  (None, 13, 15, 256)  262400     ['activation_285[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv5x_3_branch2a (BatchNor  (None, 13, 15, 256)  52         ['res2conv5x_3_branch2a[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_286 (Activation)    (None, 13, 15, 256)  0           ['bn2conv5x_3_branch2a[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv5x_3_branch2b (Conv2D)  (None, 11, 13, 256)  590080     ['activation_286[0][0]']         \n",
      "                                                                                                  \n",
      " bn2conv5x_3_branch2b (BatchNor  (None, 11, 13, 256)  44         ['res2conv5x_3_branch2b[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " activation_287 (Activation)    (None, 11, 13, 256)  0           ['bn2conv5x_3_branch2b[0][0]']   \n",
      "                                                                                                  \n",
      " res2conv5x_3_branch2c (Conv2D)  (None, 11, 13, 1024  263168     ['activation_287[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv5x_3_branch2c (BatchNor  (None, 11, 13, 1024  44         ['res2conv5x_3_branch2c[0][0]']  \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " res2conv5x_3_branch-shortcut (  (None, 11, 13, 1024  9438208    ['activation_285[0][0]']         \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_288 (Activation)    (None, 11, 13, 1024  0           ['bn2conv5x_3_branch2c[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn2conv5x_3_branch-shortcut (B  (None, 11, 13, 1024  44         ['res2conv5x_3_branch-shortcut[0]\n",
      " atchNormalization)             )                                [0]']                            \n",
      "                                                                                                  \n",
      " add_69 (Add)                   (None, 11, 13, 1024  0           ['activation_288[0][0]',         \n",
      "                                )                                 'bn2conv5x_3_branch-shortcut[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_289 (Activation)    (None, 11, 13, 1024  0           ['add_69[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D)    (None, 5, 6, 1024)   0           ['activation_289[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 30720)        0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " first_dense (Dense)            (None, 512)          15729152    ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " second_dense (Dense)           (None, 100)          51300       ['first_dense[0][0]']            \n",
      "                                                                                                  \n",
      " fc_outputs (Dense)             (None, 1)            101         ['second_dense[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 56,653,929\n",
      "Trainable params: 56,649,497\n",
      "Non-trainable params: 4,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "steps_per_epoch = math.ceil(5000 / BATCH_SIZE)\n",
    "print(steps_per_epoch)\n",
    "res = ResNetJ(feature=\"energy\", epochs=EPOCHS, steps_per_epoch=steps_per_epoch)\n",
    "res.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a learning rate which increase in the first epoch from $0$ to $10^{-3}$, and then decrease from $10^{-3}$ to $10^{-8}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def step_decay_schedule(initial_lr=1e-8, decay_factor=0.75, step_size=10, BS=64, ndat = 5e6):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        if epoch==1:\n",
    "            decay_factor = 10**(-3) * BS / ndat\n",
    "            lr_sched = initial_lr * decay_factor     #(decay_factor ** np.floor(epoch/step_size))\n",
    "            return lr_sched\n",
    "        else:\n",
    "            decay_factor = 0.1\n",
    "            lr_sched = tk.optimizers.schedules.ExponentialDecay(initial_learning_rate=10**(-3) )\n",
    "            return lr_sched\n",
    "#        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=1e-4)\n",
    "\n",
    "# setting an adaptive learning rate\n",
    "\n",
    "# def adapt_learning_rate(epoch):\n",
    "#     if(epoch==1):\n",
    "#         lr = 0.001\n",
    "#     elif(epoch!=1):\n",
    "#         lr = 0.1*epoch\n",
    "#     return lr\n",
    "\n",
    "# lr_history = tk.callbacks.Callback.LearningRate()\n",
    "# lr_rate = tk.callbacks.LearningRateScheduler(adapt_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/\" + date_time\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, update_freq=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\n",
      "reading file:\n",
      "\tfilename: ../../juno_data/data/projections/proj_raw_data_train_304.npz \n",
      "\tlabelfile: ../../juno_data/data/real/train/targets/targets_train_304.csv\n",
      "     79/Unknown - 67s 709ms/step - loss: 15.4100 - root_mean_squared_error: 3.9256"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 0.9896444748193868 to EagerTensor of dtype int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39;49mfit(ds,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m          epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000017vscode-remote?line=2'>3</a>\u001b[0m          callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000017vscode-remote?line=3'>4</a>\u001b[0m          shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/juno_data/anaconda3V100/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ubuntu/juno_data/anaconda3V100/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/juno_data/anaconda3V100/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/ubuntu/juno_data/anaconda3V100/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/ubuntu/juno_data/anaconda3V100/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/ubuntu/juno_data/anaconda3V100/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb Cell 9'\u001b[0m in \u001b[0;36mMyLRSchedule.__call__\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, step):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=10'>11</a>\u001b[0m   result \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcond(tf\u001b[39m.\u001b[39;49mless(step, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps_per_epoch), \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=11'>12</a>\u001b[0m                  \u001b[39mlambda\u001b[39;49;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm \u001b[39m*\u001b[39;49m (step\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=12'>13</a>\u001b[0m                  \u001b[39mlambda\u001b[39;49;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_learning_rate \u001b[39m*\u001b[39;49m tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mpow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecay_rate, (step\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps_per_epoch)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=14'>15</a>\u001b[0m   tf\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mlr at step\u001b[39m\u001b[39m'\u001b[39m, step, \u001b[39m'\u001b[39m\u001b[39mis\u001b[39m\u001b[39m'\u001b[39m, result, output_stream\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfile://learning_rates.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=15'>16</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m result  \n",
      "\u001b[1;32m/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb Cell 9'\u001b[0m in \u001b[0;36mMyLRSchedule.__call__.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, step):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=10'>11</a>\u001b[0m   result \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcond(tf\u001b[39m.\u001b[39mless(step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps_per_epoch), \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=11'>12</a>\u001b[0m                  \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m*\u001b[39m (step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=12'>13</a>\u001b[0m                  \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_learning_rate \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mpow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecay_rate, (step\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps_per_epoch)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=14'>15</a>\u001b[0m   tf\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mlr at step\u001b[39m\u001b[39m'\u001b[39m, step, \u001b[39m'\u001b[39m\u001b[39mis\u001b[39m\u001b[39m'\u001b[39m, result, output_stream\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfile://learning_rates.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm2-cv/home/ubuntu/qcnn4juno/resnet/Juno_resnet.ipynb#ch0000008vscode-remote?line=15'>16</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m result  \n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 0.9896444748193868 to EagerTensor of dtype int64"
     ]
    }
   ],
   "source": [
    "\n",
    "history = res.fit(ds,\n",
    "         epochs=EPOCHS,\n",
    "         callbacks=[tensorboard_callback],\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(n,k,s):\n",
    "    n_out = (n-k)/s + 1\n",
    "    return n_out\n",
    "f(26,25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1(X, block=\"conv1\", stage=2):\n",
    "            \n",
    "        # defining name basis\n",
    "        conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "        \n",
    "        X_input = X\n",
    "        # First component of main path\n",
    "        X = Conv2D(64, kernel_size = (6,3), strides = (2,1),\n",
    "                name = conv_name_base + '2a',\n",
    "                #nchannels??\n",
    "                # data_format=\"channels_first\", \n",
    "                # kernel_initializer = glorot_uniform(seed=0)\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis = 1, name = bn_name_base + '2a')(X)\n",
    "        X = Activation('relu')(X)\n",
    "        \n",
    "        # Second component of main path\n",
    "        X = Conv2D(64, kernel_size = (3,3), strides = (2,2),\n",
    "                name = conv_name_base + '2b',\n",
    "                #nchannels?? \n",
    "                # kernel_initializer = glorot_uniform(seed=0)\n",
    "                )(X)\n",
    "        X = BatchNormalization(axis=1, name = bn_name_base + '2b')(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = MaxPooling2D((2,2), strides=(1,1))(X)\n",
    "        \n",
    "        # Create model\n",
    "        model = Model(inputs = X_input, outputs = X, name = 'ResNetJ')\n",
    "        \n",
    "        # Compile model\n",
    "        learning_rate = 1e-3\n",
    "        opt = tk.optimizers.Adam(learning_rate=learning_rate, beta_1 = 0.9, beta_2 = 0.999 )\n",
    "\n",
    "        model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=['accuracy'])\n",
    "        \n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetJ\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 230, 124, 2)]     0         \n",
      "                                                                 \n",
      " res2conv1_branch2a (Conv2D)  (None, 113, 122, 64)     2368      \n",
      "                                                                 \n",
      " bn2conv1_branch2a (BatchNor  (None, 113, 122, 64)     452       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " activation_230 (Activation)  (None, 113, 122, 64)     0         \n",
      "                                                                 \n",
      " res2conv1_branch2b (Conv2D)  (None, 56, 60, 64)       36928     \n",
      "                                                                 \n",
      " bn2conv1_branch2b (BatchNor  (None, 56, 60, 64)       224       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " activation_231 (Activation)  (None, 56, 60, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 55, 59, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,972\n",
      "Trainable params: 39,634\n",
      "Non-trainable params: 338\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_input = Input(shape=(230,124,2))\n",
    "res1 = conv1(X_input)\n",
    "res1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # \"\"\"\n",
    "    # prova\n",
    "    # \"\"\"\n",
    "    # # Stage 1\n",
    "    # X = conv1(X_input, block=\"conv1\")\n",
    "    # # Stage2\n",
    "    # X = conv2x(X, stride=1, filters=[64,256], block=\"conv2x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[64,256], block=\"conv2x_2\")\n",
    "    # X = conv2x(X, stride=1, filters=[64,256], block=\"conv2x_3\")\n",
    "\n",
    "    # # Stage 3\n",
    "    # X = conv2x(X, stride=1, filters=[64,256], block=\"conv3x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[128,512], block=\"conv3x_2\")\n",
    "    # X = conv2x(X, stride=1, filters=[128,512], block=\"conv3x_3\")\n",
    "    # X = conv2x(X, stride=1, filters=[128,512], block=\"conv3x_4\")\n",
    "\n",
    "    # # Stage 4 \n",
    "    # X = conv2x(X, stride=1, filters=[128,512], block=\"conv4x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_2\")\n",
    "    # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_3\")\n",
    "    # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_4\")\n",
    "    # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_5\")\n",
    "    # X = conv2x(X, stride=1, filters=[256,1024], block=\"conv4x_6\")\n",
    "\n",
    "    # # Stage 5\n",
    "    # X = conv2x(X, stride=1, filters=[512,2048], block=\"conv5x_1\")\n",
    "    # X = conv2x(X, stride=1, filters=[512,2048], block=\"conv5x_2\")\n",
    "    # X = conv2x(X, stride=1, filters=[512,2048], block=\"conv5x_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('learning_rates.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "lr = np.zeros((len(lines), 2))\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    data = re.findall(\"[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?\\d+)?\", line)\n",
    "    lr[i, :] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb8676ba60>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lr[:419,1])\n",
    "plt.plot(lr[419:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrainfiles = 1\n",
    "\n",
    "filelist = glob.glob('../../juno_data/data/projections/*.npz')\n",
    "filelist = filelist[:ntrainfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******READ DATA*******#\n",
    "def get_data_from_filename(filename):\n",
    "   labelfile = '../../juno_data/data/real/train/targets/targets_train_{}.csv'.format(re.findall('\\d+', filename.decode())[0])\n",
    "   print('\\nreading file:\\n\\tfilename:', filename.decode(), '\\n\\tlabelfile:', labelfile)\n",
    "   labeldata = pd.read_csv(labelfile)\n",
    "   labeldata = labeldata['edep'].to_numpy()\n",
    "   npdata = np.load(filename, allow_pickle=True)['arr_0']\n",
    "   npdata[tf.math.is_nan(npdata)] = 0\n",
    "   return (npdata, labeldata)\n",
    "\n",
    "def get_data_wrapper(filename):\n",
    "   # Assuming here that both your data and label is double type\n",
    "   features, labels = tf.numpy_function(\n",
    "       get_data_from_filename, [filename], (tf.float64, tf.float64)) \n",
    "   return tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Create dataset of filenames.\n",
    "ds = tf.data.Dataset.from_tensor_slices(filelist)\n",
    "ds = ds.flat_map(get_data_wrapper).prefetch(tf.data.AUTOTUNE).batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: ../../juno_data/data/projections/proj_raw_data_train_304.npz \n",
      "labelfile: ../../juno_data/data/real/train/targets/targets_train_304.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(64, 230, 124, 2), dtype=float64, numpy=\n",
       "  array([[[[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]],\n",
       "  \n",
       "          [[0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           ...,\n",
       "           [0., 0.],\n",
       "           [0., 0.],\n",
       "           [0., 0.]]]])>,\n",
       "  <tf.Tensor: shape=(64,), dtype=float64, numpy=\n",
       "  array([ 1.06192899,  3.34897041,  9.00979137,  3.19611788,  7.62453222,\n",
       "          2.11519432,  3.39153481,  6.2750473 ,  4.85691738,  3.39822316,\n",
       "          7.35028028,  6.61850452,  1.42082226,  3.65491724,  3.75981212,\n",
       "          6.35347462,  9.89048386,  9.43706799,  8.19062042,  4.33964443,\n",
       "          6.90976906,  4.51742363,  3.73068666,  2.49369454,  3.29576206,\n",
       "          2.46365213,  8.2917738 ,  9.54415417,  2.60754681,  4.3138361 ,\n",
       "          8.03799915, 10.92156124,  9.09370518,  4.22572374,  8.73578453,\n",
       "          4.04712057,  4.08431768,  4.01205635,  6.55668926,  2.04302621,\n",
       "          5.95078087,  7.23278284,  1.68279207,  8.96160507,  5.14284897,\n",
       "          4.54260254, 10.87402534,  2.01476741,  2.45525026, 10.67197514,\n",
       "          7.29769611,  5.45833778,  2.0159924 ,  1.62780738, 10.19994068,\n",
       "          4.49297428,  2.33994913,  9.25212383,  1.46575773,  5.75683689,\n",
       "          7.26291466,  6.10979986,  7.95593071, 10.72086048])>)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'304'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d+', filelist[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../juno_data/data/projections/proj_raw_data_train_471.npz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f349c0f5a8952588bcff4d87e290f0f7b7be69b2eaf4ab59894e0ae7d78e8b51"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
